{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().resolve().parents[0]))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_scatter import scatter_mean\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from chemrar_test.prepare import MoleculeDataset\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available:\", torch.cuda.get_device_name(0))\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pytorch_lightning.trainer.connectors.data_connector\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"lightning_fabric.plugins.environments.slurm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting to load dataset...\")\n",
    "\n",
    "dataset = torch.load(\"../data/processed/data_graph.pt\")\n",
    "\n",
    "print(\"Dataset loaded successfully. Length of dataset:\", len(dataset))\n",
    "\n",
    "molecule_dataset = dataset\n",
    "print(\"First element of the dataset:\", molecule_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Loading split data...\")\n",
    "split_path = \"/home/nikolenko/work/Project/ChemRar/data/processed/random_split.csv\"\n",
    "split_df = pd.read_csv(split_path)\n",
    "print(\"Split data loaded successfully.\")\n",
    "\n",
    "# %%\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "print(\"Splitting dataset into train, validation, and test sets...\")\n",
    "\n",
    "# Создание словарей для быстрого поиска\n",
    "train_smiles_set = set(split_df['Train_SMILES'])\n",
    "val_smiles_set = set(split_df['Val_SMILES'])\n",
    "test_smiles_set = set(split_df['Test_SMILES'])\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "# Используем tqdm для отображения прогресса\n",
    "for data in tqdm(molecule_dataset, desc=\"Splitting dataset\"):\n",
    "    smiles = data.smiles\n",
    "\n",
    "    if smiles in train_smiles_set:\n",
    "        train_data.append(data)\n",
    "    elif smiles in val_smiles_set:\n",
    "        val_data.append(data)\n",
    "    elif smiles in test_smiles_set:\n",
    "        test_data.append(data)\n",
    "\n",
    "print(f\"Split completed. Train set: {len(train_data)}, Val set: {len(val_data)}, Test set: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedMoleculeModel(pl.LightningModule):\n",
    "    def __init__(self, atom_in_features, edge_in_features, hidden_features, num_heads, dropout_rates, out_features, learning_rate, weight_decay, batch_size, linear_layer_sizes, step_size, gamma):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.batch_size = batch_size\n",
    "        self.test_outputs = []\n",
    "\n",
    "        atom_layers = []\n",
    "        edge_layers = []\n",
    "        input_size = atom_in_features\n",
    "        for i in range(len(linear_layer_sizes)):\n",
    "            output_size = linear_layer_sizes[i]\n",
    "            atom_layers.extend([\n",
    "                nn.Linear(input_size, output_size),\n",
    "                nn.BatchNorm1d(output_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(dropout_rates)\n",
    "            ])\n",
    "            edge_layers.extend([\n",
    "                nn.Linear(edge_in_features if i == 0 else linear_layer_sizes[i-1], output_size),\n",
    "                nn.BatchNorm1d(output_size),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(dropout_rates)\n",
    "            ])\n",
    "            input_size = output_size\n",
    "\n",
    "        self.atom_preprocess = nn.Sequential(*atom_layers)\n",
    "        self.edge_preprocess = nn.Sequential(*edge_layers)\n",
    "        \n",
    "        self.gat_conv1 = GATv2Conv(\n",
    "            in_channels=hidden_features, \n",
    "            out_channels=hidden_features, \n",
    "            heads=num_heads[0], \n",
    "            concat=True, \n",
    "            dropout=dropout_rates,\n",
    "            edge_dim=input_size\n",
    "        )\n",
    "\n",
    "        self.gat_conv2 = GATv2Conv(\n",
    "            in_channels=hidden_features * num_heads[0], \n",
    "            out_channels=hidden_features, \n",
    "            heads=num_heads[1], \n",
    "            concat=True, \n",
    "            dropout=dropout_rates\n",
    "        )\n",
    "        \n",
    "        self.postprocess = nn.Sequential(\n",
    "            nn.Linear(hidden_features * num_heads[1], hidden_features),\n",
    "            nn.BatchNorm1d(hidden_features),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout_rates),\n",
    "            nn.Linear(hidden_features, out_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        edge_index = edge_index.long()\n",
    "        x = self.atom_preprocess(x)\n",
    "        edge_attr = self.edge_preprocess(edge_attr)\n",
    "        \n",
    "        x = self.gat_conv1(x, edge_index, edge_attr=edge_attr)\n",
    "        x = self.gat_conv2(x, edge_index)\n",
    "        \n",
    "        x = self.postprocess(x).squeeze(-1)\n",
    "        return x\n",
    "            \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch.batch = batch.batch.long()\n",
    "        x = self(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        y_hat = scatter_mean(x, batch.batch, dim=0)\n",
    "        loss = nn.BCEWithLogitsLoss()(y_hat, batch.y.float())\n",
    "        self.log('train_loss', loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch.batch = batch.batch.long()\n",
    "        x = self(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        y_hat = scatter_mean(x, batch.batch, dim=0)\n",
    "        val_loss = nn.BCEWithLogitsLoss()(y_hat, batch.y.float())\n",
    "        self.log('val_loss', val_loss, batch_size=self.batch_size)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        batch.batch = batch.batch.long()\n",
    "        x = self(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        y_hat = scatter_mean(x, batch.batch, dim=0)\n",
    "        y_pred = torch.sigmoid(y_hat).cpu().numpy()\n",
    "        y_true = batch.y.float().cpu().numpy()\n",
    "        self.test_outputs.append({'y_pred': y_pred, 'y_true': y_true})\n",
    "\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = StepLR(optimizer, step_size=self.hparams.step_size, gamma=self.hparams.gamma)  # Планировщик на основе шага\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        y_pred = np.concatenate([o['y_pred'] for o in self.test_outputs])\n",
    "        y_true = np.concatenate([o['y_true'] for o in self.test_outputs])\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred.round())\n",
    "        precision = precision_score(y_true, y_pred.round(), zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred.round(), zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred.round(), zero_division=0)\n",
    "        \n",
    "        if len(np.unique(y_true)) > 1:\n",
    "            roc_auc = roc_auc_score(y_true, y_pred)\n",
    "            pr_auc = average_precision_score(y_true, y_pred)\n",
    "        else:\n",
    "            roc_auc = float('nan')\n",
    "            pr_auc = float('nan')\n",
    "        \n",
    "        self.log_dict({\n",
    "            'test_accuracy': accuracy,\n",
    "            'test_precision': precision,\n",
    "            'test_recall': recall,\n",
    "            'test_f1': f1,\n",
    "            'test_roc_auc': roc_auc,\n",
    "            'test_pr_auc': pr_auc\n",
    "        })\n",
    "        print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}, PR-AUC: {pr_auc:.4f}')\n",
    "        print(\"Test results logged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"../reports/gatv2_log\", name=\"molecule_model\")\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    log_every_n_steps=10,\n",
    "    logger=logger,\n",
    "    callbacks=[early_stop_callback],\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "atom_in_features = train_data[0].num_features\n",
    "edge_in_features = train_data[0].num_edge_features\n",
    "hidden_features = 128\n",
    "num_heads = [32, 16]\n",
    "dropout_rates = 0.2\n",
    "out_features = 1\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5\n",
    "batch_size = 1024\n",
    "linear_layer_sizes = [128, 128] \n",
    "step_size = 20\n",
    "gamma = 0.1\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = SimplifiedMoleculeModel(\n",
    "    atom_in_features=atom_in_features,\n",
    "    edge_in_features=edge_in_features,\n",
    "    hidden_features=hidden_features,\n",
    "    num_heads=num_heads,\n",
    "    dropout_rates=dropout_rates,\n",
    "    out_features=out_features,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    linear_layer_sizes=linear_layer_sizes,\n",
    "    step_size=step_size,\n",
    "    gamma=gamma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/gatv2_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geom_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
