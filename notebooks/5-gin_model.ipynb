{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: NVIDIA H100 PCIe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().resolve().parents[0]))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.nn import GINConv\n",
    "from torch_scatter import scatter_mean\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "import numpy as np\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from chemrar_test.prepare import MoleculeDataset\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available:\", torch.cuda.get_device_name(0))\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pytorch_lightning.trainer.connectors.data_connector\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"lightning_fabric.plugins.environments.slurm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully. Length of dataset: 367465\n",
      "First element of the dataset: Data(x=[82, 133], edge_index=[2, 176], edge_attr=[176, 14], y=1, smiles='Cc1cncc(C(=O)Nc2ccc3c(c2)nc(CN2CCC(Oc4ccnc(Cc5ccc(Cl)cc5)n4)CC2)n3CC2CCO2)c1')\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting to load dataset...\")\n",
    "\n",
    "dataset = torch.load(\"../data/processed/data_graph.pt\")\n",
    "\n",
    "print(\"Dataset loaded successfully. Length of dataset:\", len(dataset))\n",
    "\n",
    "molecule_dataset = dataset\n",
    "print(\"First element of the dataset:\", molecule_dataset[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading split data...\n",
      "Split data loaded successfully.\n",
      "Splitting dataset into train, validation, and test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting dataset: 100%|██████████| 367465/367465 [03:20<00:00, 1830.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split completed. Train set: 220479, Val set: 73493, Test set: 73493\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Loading split data...\")\n",
    "split_path = \"/home/nikolenko/work/Project/ChemRar/data/processed/random_split.csv\"\n",
    "split_df = pd.read_csv(split_path)\n",
    "print(\"Split data loaded successfully.\")\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "print(\"Splitting dataset into train, validation, and test sets...\")\n",
    "\n",
    "train_smiles_set = set(split_df['Train_SMILES'])\n",
    "val_smiles_set = set(split_df['Val_SMILES'])\n",
    "test_smiles_set = set(split_df['Test_SMILES'])\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "for data in tqdm(molecule_dataset, desc=\"Splitting dataset\"):\n",
    "    smiles = data.smiles\n",
    "\n",
    "    if smiles in train_smiles_set:\n",
    "        train_data.append(data)\n",
    "    elif smiles in val_smiles_set:\n",
    "        val_data.append(data)\n",
    "    elif smiles in test_smiles_set:\n",
    "        test_data.append(data)\n",
    "\n",
    "print(f\"Split completed. Train set: {len(train_data)}, Val set: {len(val_data)}, Test set: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomEdgeInteraction(nn.Module):\n",
    "    def __init__(self, in_features, edge_features, out_features, edge_importance=1.0, dropout_rate=0.1, use_batch_norm=True):\n",
    "        super(AtomEdgeInteraction, self).__init__()\n",
    "        self.edge_importance = edge_importance\n",
    "        self.interaction = nn.Linear(in_features + edge_features, out_features)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.batch_norm = nn.BatchNorm1d(out_features) if use_batch_norm else nn.Identity()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.residual = nn.Linear(in_features, out_features) if in_features != out_features else nn.Identity()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        row, col = edge_index\n",
    "        edge_features = edge_attr * self.edge_importance\n",
    "        atom_features = x[row]\n",
    "        combined_features = torch.cat([atom_features, edge_features], dim=-1)\n",
    "        updated_features = self.interaction(combined_features)\n",
    "        updated_features = self.activation(updated_features)\n",
    "        updated_features = self.batch_norm(updated_features)\n",
    "        updated_features = self.dropout(updated_features)\n",
    "        residual_features = self.residual(x)\n",
    "        x = scatter_mean(updated_features, col, dim=0, dim_size=x.size(0))\n",
    "        return x + residual_features\n",
    "\n",
    "from torch_geometric.nn import GINConv\n",
    "\n",
    "class SimplifiedMoleculeModel(pl.LightningModule):\n",
    "    def __init__(self, atom_in_features, edge_in_features, hidden_features, dropout_rates, out_features, learning_rate, weight_decay, batch_size, linear_layer_sizes, step_size, gamma):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.batch_size = batch_size\n",
    "        self.test_outputs = []\n",
    "\n",
    "        self.atom_edge_interaction1 = AtomEdgeInteraction(\n",
    "            in_features=atom_in_features,\n",
    "            edge_features=edge_in_features,\n",
    "            out_features=hidden_features,\n",
    "            dropout_rate=dropout_rates\n",
    "        )\n",
    "\n",
    "        nn1 = nn.Sequential(\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.gin_conv1 = GINConv(nn1)\n",
    "\n",
    "        self.postprocess = nn.Sequential(\n",
    "            nn.Linear(hidden_features, hidden_features),\n",
    "            nn.BatchNorm1d(hidden_features),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout_rates),\n",
    "            nn.Linear(hidden_features, out_features)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.atom_edge_interaction1(x, edge_index, edge_attr)\n",
    "        x = self.gin_conv1(x, edge_index)\n",
    "        x = nn.ELU()(x)\n",
    "        \n",
    "        x = self.postprocess(x).squeeze(-1)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = self(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        y_hat = scatter_mean(x, batch.batch, dim=0)\n",
    "        loss = nn.BCEWithLogitsLoss()(y_hat, batch.y.float())\n",
    "        self.log('train_loss', loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = self(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        y_hat = scatter_mean(x, batch.batch, dim=0)\n",
    "        val_loss = nn.BCEWithLogitsLoss()(y_hat, batch.y.float())\n",
    "        self.log('val_loss', val_loss, batch_size=self.batch_size)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = self(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        y_hat = scatter_mean(x, batch.batch, dim=0)\n",
    "        y_pred = torch.sigmoid(y_hat).cpu().numpy()\n",
    "        y_true = batch.y.float().cpu().numpy()\n",
    "        self.test_outputs.append({'y_pred': y_pred, 'y_true': y_true})\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = StepLR(optimizer, step_size=self.hparams.step_size, gamma=self.hparams.gamma)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        y_pred = np.concatenate([o['y_pred'] for o in self.test_outputs])\n",
    "        y_true = np.concatenate([o['y_true'] for o in self.test_outputs])\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred.round())\n",
    "        precision = precision_score(y_true, y_pred.round(), zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred.round(), zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred.round(), zero_division=0)\n",
    "        \n",
    "        if len(np.unique(y_true)) > 1:\n",
    "            roc_auc = roc_auc_score(y_true, y_pred)\n",
    "            pr_auc = average_precision_score(y_true, y_pred)\n",
    "        else:\n",
    "            roc_auc = float('nan')\n",
    "            pr_auc = float('nan')\n",
    "        \n",
    "        self.log_dict({\n",
    "            'test_accuracy': accuracy,\n",
    "            'test_precision': precision,\n",
    "            'test_recall': recall,\n",
    "            'test_f1': f1,\n",
    "            'test_roc_auc': roc_auc,\n",
    "            'test_pr_auc': pr_auc\n",
    "        })\n",
    "        print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}, PR-AUC: {pr_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"../reports/gatv2_log\", name=\"molecule_model\")\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    verbose=True\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    log_every_n_steps=10,\n",
    "    logger=logger,\n",
    "    callbacks=[early_stop_callback],\n",
    "    enable_progress_bar=False\n",
    "\n",
    ")\n",
    "\n",
    "atom_in_features = dataset.num_features\n",
    "edge_in_features = dataset.num_edge_features\n",
    "hidden_features = 128\n",
    "dropout_rates = 0.2\n",
    "out_features = 1\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-5\n",
    "batch_size = 1024\n",
    "linear_layer_sizes = [128, 128] \n",
    "step_size = 20\n",
    "gamma = 0.1\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = SimplifiedMoleculeModel(\n",
    "    atom_in_features=atom_in_features,\n",
    "    edge_in_features=edge_in_features,\n",
    "    hidden_features=hidden_features,\n",
    "    dropout_rates=dropout_rates,\n",
    "    out_features=out_features,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    batch_size=batch_size,\n",
    "    linear_layer_sizes=linear_layer_sizes,\n",
    "    step_size=step_size,\n",
    "    gamma=gamma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name                   | Type                | Params\n",
      "---------------------------------------------------------------\n",
      "0 | atom_edge_interaction1 | AtomEdgeInteraction | 36.4 K\n",
      "1 | gin_conv1              | GINConv             | 33.0 K\n",
      "2 | postprocess            | Sequential          | 16.9 K\n",
      "---------------------------------------------------------------\n",
      "86.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "86.3 K    Total params\n",
      "0.345     Total estimated model params size (MB)\n",
      "/home/nikolenko/miniforge3/envs/torch/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "Metric val_loss improved. New best score: 0.702\n",
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.690\n",
      "Metric val_loss improved by 0.016 >= min_delta = 0.0. New best score: 0.675\n",
      "Metric val_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.656\n",
      "Metric val_loss improved by 0.022 >= min_delta = 0.0. New best score: 0.634\n",
      "Metric val_loss improved by 0.026 >= min_delta = 0.0. New best score: 0.608\n",
      "Metric val_loss improved by 0.030 >= min_delta = 0.0. New best score: 0.579\n",
      "Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.547\n",
      "Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.515\n",
      "Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.483\n",
      "Metric val_loss improved by 0.030 >= min_delta = 0.0. New best score: 0.453\n",
      "Metric val_loss improved by 0.029 >= min_delta = 0.0. New best score: 0.424\n",
      "Metric val_loss improved by 0.026 >= min_delta = 0.0. New best score: 0.398\n",
      "Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.374\n",
      "Metric val_loss improved by 0.022 >= min_delta = 0.0. New best score: 0.352\n",
      "Metric val_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.332\n",
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.314\n",
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.299\n",
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.286\n",
      "Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.275\n",
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.266\n",
      "Metric val_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.258\n",
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.251\n",
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.246\n",
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.241\n",
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.237\n",
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.234\n",
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.232\n",
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.231\n",
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.229\n",
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.229\n",
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.229. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000, ROC-AUC: nan, PR-AUC: nan\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy                 1.0\n",
      "         test_f1                    1.0\n",
      "       test_pr_auc                  nan\n",
      "     test_precision                 1.0\n",
      "       test_recall                  1.0\n",
      "      test_roc_auc                  nan\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_accuracy': 1.0,\n",
       "  'test_precision': 1.0,\n",
       "  'test_recall': 1.0,\n",
       "  'test_f1': 1.0,\n",
       "  'test_roc_auc': nan,\n",
       "  'test_pr_auc': nan}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/gcn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/gin_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geom_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
